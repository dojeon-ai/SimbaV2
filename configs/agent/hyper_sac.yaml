##################################################################################
# Soft Actor-Critic with Hyper-Simba architecture
##################################################################################

agent_type: 'hyper_sac'

seed: ${seed}
num_train_envs: ${env.num_train_envs}
max_episode_steps: ${env.max_episode_steps}
normalize_observation: true

actor_num_blocks: 1
actor_hidden_dim: 128
actor_learning_rate_init: 1e-4
actor_learning_rate_end: 1e-4
actor_learning_rate_decay_rate: 1.0 
actor_learning_rate_decay_step: ${eval:'int(${agent.actor_learning_rate_decay_rate} * ${num_interaction_steps} * ${updates_per_interaction_step})'}
actor_input_projection_type: 'shift'
actor_input_projection_constant: 3.0
actor_alpha_init: ${eval:'1 / (${agent.actor_num_blocks} + 1)'}
actor_alpha_scale: ${eval:'1 / math.sqrt(${agent.actor_hidden_dim})'}
actor_output_hidden_dim: 128

critic_num_blocks: 2
critic_hidden_dim: 512
critic_learning_rate_init: 1e-4
critic_learning_rate_end: 1e-4
critic_learning_rate_decay_rate: 1.0 
critic_learning_rate_decay_step: ${eval:'int(${agent.critic_learning_rate_decay_rate} * ${num_interaction_steps} * ${updates_per_interaction_step})'}
critic_use_cdq: ${env.episodic}
critic_input_projection_type: 'shift'
critic_input_projection_constant: 3.0
critic_alpha_init: ${eval:'1 / (${agent.critic_num_blocks} + 1)'}
critic_alpha_scale: ${eval:'1 / math.sqrt(${agent.critic_hidden_dim})'}
critic_output_hidden_dim: 512

temp_target_entropy: null # entropy_coef * action_dim
temp_target_entropy_coef: -0.5 
temp_initial_value: 0.01
temp_learning_rate: 1e-4

target_tau: 0.005
target_normalize_weight: false
gamma: ${gamma}
n_step: ${n_step}

mixed_precision: false
